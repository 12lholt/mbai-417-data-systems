{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIgdzbPdvfMtjo4A6Er5uY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brook-miller/mbai-417-data/blob/main/enterprise-data-quality/homework/homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K Console \n",
        "\n",
        "### Situation\n",
        "The K Console is a console gaming platform that competes with other video game console systems such as: Nintendo Switch, Sony Playstation & Microsoft XBox.\n",
        "\n",
        "It's early 2020 and the team at K Console is looking to optimize production for the K Console for the rest of the year and particularly the holiday season.  \n",
        "\n",
        "The K Console marketing team recently acquired â€œsocial data\". The social data are metrics collected from a variety of social media sources: reddit, twitter, blogs, forums and even podcast transcripts to find posts mentioning the K console and score those posts based on sentiment.  The volume metric highlights the weekly volume of social posts from a set of specific, highly influential sources.  The sentiment metrics score the number of positive, negative, neutral and unassigned posts for each week.\n",
        "\n",
        "The marketing team has had success in using social data to understand & respond to customer concerns, as well as identify content ideas that resonate with influencers, but it has not been used as an input to forecasting future sales.\n",
        "\n",
        "### Analysis\n",
        "\n",
        "Should the K Console team invest resources (>$100k estimated costs) of the data science / engineering teams to build a data pipeline and update forecast models with social data to deliver better forecasts for production planning?\n",
        "\n",
        "### Data\n",
        "The data is in 3 files: \n",
        "* k-console-activations-final.csv the number of new activations by consumers (we don't know exact sales dates as the product is primarily sold through retail) but activations are a solid if lagging indicator of sales\n",
        "* k-console-social-sentiment-final.csv contains 4 different measures of sentiment (positive, negative, neutral, unassigned)\n",
        "* k-console-social-volume-final.csv the volume of social media posts mentioning the k console\n"
      ],
      "metadata": {
        "id": "QLsNzqelHwkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title standard imports - we'll use in most EDA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.parser import parse\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "0L5EcNQ8LCKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the source data into individual data frames"
      ],
      "metadata": {
        "id": "y4Zd9xBsLMmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activations_df = pd.read_csv('https://raw.githubusercontent.com/brook-miller/mbai-417-data/main/enterprise-data-quality/homework/k-console-activations-final.csv')\n",
        "sentiment_df = pd.read_csv('https://raw.githubusercontent.com/brook-miller/mbai-417-data/main/enterprise-data-quality/homework/k-console-social-sentiment-final.csv')\n",
        "volume_df = pd.read_csv('https://raw.githubusercontent.com/brook-miller/mbai-417-data/main/enterprise-data-quality/homework/k-console-social-volume-final.csv')"
      ],
      "metadata": {
        "id": "YZ60kPubLZvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View each data frame, verify the data types are appropriate\n",
        "\n",
        "In addition to casting the date values, one of the columns includes \",\" as a thousands separator.  The pd.to_numeric function can help can convert that data to a numeric type.\n",
        "\n",
        "```\n",
        "pd.to_numeric(activations_dataframe[\"activations\"].str.replace(\",\",\"\"))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "f0XMnZkhLmeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title code here, add additional code cells as necessary"
      ],
      "metadata": {
        "id": "tCTvSOsyLl5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter each data frame to the United States data only"
      ],
      "metadata": {
        "id": "5K0FXEtPLyfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title code here, add additional code cells as necessary"
      ],
      "metadata": {
        "id": "I7Sbf2GELyXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter, pivot and merge the data into a single dataframe by joining on dates\n",
        "\n",
        "At the end of this section you should have columns for each metric: activations, volume, positive, negative, neutral & unassigned.\n",
        "\n",
        "To get there you will need to pivot on the sentiment data frame and update the activations data to align the dates with the sentiment and volume dataframes.  Use the pandas merge function to combine the 3 datasets into one. (2 paired merges)\n",
        "\n",
        "You may want to drop unnecessary columns and/or reorder them for convenience.\n",
        "\n",
        "```\n",
        "activations_dataframe[\"new_column_name\"] = activations_dataframe[\"week_end_date\"].apply(lambda x : x - timedelta(days=X))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tZCLcBCeMPC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title code here, add additional code cells as necessary"
      ],
      "metadata": {
        "id": "pkp_IJ0qZwAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determine if there is missing data, fill in any missing data"
      ],
      "metadata": {
        "id": "_VIWrVDFL8Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title code here, add additional code cells as necessary\n"
      ],
      "metadata": {
        "id": "Ot8lSU76L74j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph the data, analyze to determine if additional efforts are worthwhile\n",
        "\n",
        "You can manually scale (normalize) each of the columns or use MinMaxScaler\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#cols contains the list of columns you want to scale activations, volume, etc...\n",
        "normalized_dataframe = pd.DataFrame(scaler.fit_transform(final_dataframe[cols]), columns=cols)\n",
        "\n",
        "#add the date column to the normalized_dataframe\n",
        "normalized_dataframe[\"week_start_date\"] = final_dataframe[\"week_start_date\"]\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "hW1qv_BYNHcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title code here, add additional code cells as necessary\n"
      ],
      "metadata": {
        "id": "6Y-uM_E4NHRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Final analysis\n",
        "In the markdown cell below summarize your findings. What method did you use to fill in the missing data? Should the team invest additional resources to build better models linking activations to social metrics.  \n",
        "\n",
        "While you may be inclined to do additional analysis, this is a decision making under uncertainty exercise.  There are many other projects K Console team could focus on.  \n",
        "\n",
        "Please limit your response to 250 words (+/-)"
      ],
      "metadata": {
        "id": "AuVX_AcmNRZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*final analysis here*"
      ],
      "metadata": {
        "id": "qWIsUxvxNRRw"
      }
    }
  ]
}